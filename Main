import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

dataset = pd.read_csv('data.csv')


  dataset

print(dataset.shape) # to know the numbers of rows and column

dataset = dataset.dropna(axis = 1) # to drop the column of missing data

print(dataset.shape)

dataset



# get the number or MALIGNENT and BENIGN
dataset['diagnosis'].value_counts()

# visualize the count
sns.countplot(dataset['diagnosis'], label= 'count')

x = dataset.iloc[:, 2:].values
y = dataset.iloc[:, 1].values

# encoding the categorical data (diagnosis)
from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
y = encoder.fit_transform(y)


print(y)

# get the correlation
plt.figure(figsize = (10,10))
sns.heatmap(dataset.iloc[:, 1:12].corr() , annot = True , fmt = '.0%' )

# spliiting the data into training and  test set (75% training and 25% test set)
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)

# FEATURE SCALING
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.fit_transform(x_test)


print(x_train)

def models(x_train,y_train):
    #LOGISTIC REGRESSION
    from sklearn.linear_model import LogisticRegression
    logistic = LogisticRegression(random_state = 0)
    logistic.fit(x_train,y_train)
    
    
    #DECISION TREE
    from sklearn.tree import DecisionTreeClassifier
    tree = DecisionTreeClassifier(criterion = 'entropy' , random_state = 0)
    tree.fit(x_train, y_train)
    
    #RANDOM FOREST
    from sklearn.ensemble import RandomForestClassifier
    random = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
    random.fit(x_train, y_train)
    
    #Print Accuracy of MODELS on TRAINING SET
    print(' 1. Logistic Regression Training Accuracy: ', logistic.score(x_train,y_train))
    print()
    print(' 2. Decision Tree Training Accuracy: ', tree.score(x_train,y_train))
    print()
    print(' 3. Random Forest  Training Accuracy: ', random.score(x_train,y_train))
    print()
    
    return logistic , tree, random


model = models(x_train, y_train)

#There  are two ways for testing the model accuracy on test set
# 1 way using confusion matrix
from sklearn.metrics import confusion_matrix
for i in range(len(model)):
    print('model ', model[i])
    cm = confusion_matrix(y_test, model[i].predict(x_test))
    tp = cm[0][0]
    tn = cm[1][1]
    fp = cm[0][1]
    fn = cm[1][0]
    
    print(cm)
    print('Testing Accuracy: ', (tp+tn)/(tp+tn+fp+fn))
    print()

# 2 way
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
for i in range(len(model)):
    print('model ', i)
    print(classification_report(y_test, model[i].predict(x_test)))
    print('Accuracy on Test Set: ',accuracy_score(y_test, model[i].predict(x_test)))
    print()
    

print('Random Forest is the Best Breast Cancer Prediction Model for this Data Set with an Accuracy of : 0.9790209790209791' )

